{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "S2_3_Statistical_Forecasting.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO553UisYZusLz+pdYhDBE/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbeucler/2022_ML_Earth_Env_Sci/blob/main/Lab_Notebooks/S2_3_Statistical_Forecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook will be used in the lab session for week 2 of the course and provides some hands-on experience applying the lessons to environmental science datasets.\n",
        "\n",
        "Need a reminder of last week's labs? Click [_here_](https://github.com/tbeucler/2022_ML_Earth_Env_Sci/blob/main/Lab_Notebooks/Week_1_Basics_of_Python.ipynb) to go to notebook for week 1 of the course."
      ],
      "metadata": {
        "id": "GAwSQhMS3TK_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Statistical Forecasting - Wilks\n",
        "\n",
        "We will be using data from Wilks' book on Statistical Methods for the Atmospheric Sciences"
      ],
      "metadata": {
        "id": "kS57AUwjmh-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "spYmkik-3K_i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_x3_GmVcKl9"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import pooch\n",
        "\n",
        "#Data Visalization Import\n",
        "from google.colab import data_table\n",
        "\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "rnd_seed = 42\n",
        "rnd_gen = np.random.default_rng(rnd_seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"classification\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's begin by loading relevant data from the cloud. "
      ],
      "metadata": {
        "id": "gQhMBs1CHqPo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loading Wilks' Table A-3 from the course datastore\n",
        "csv_path = 'https://unils-my.sharepoint.com/:x:/g/personal/tom_beucler_unil_ch/EXG7Rht55mhPiwkUKEDSI8oBuXNe8OOLYJX3_5ACmK1w5A?download=1'\n",
        "hash = 'c158828a1bdf1aa521c61321842352cb1674e49187e21c504188ab976d3a41f2'\n",
        "csv_file = pooch.retrieve(csv_path, known_hash=hash)\n",
        "\n",
        "A3_df = pd.read_csv(csv_file, index_col=0)\n",
        "\n",
        "#Display an interactive datatable for data visualization\n",
        "data_table.DataTable(A3_df, num_rows_per_page=10)"
      ],
      "metadata": {
        "id": "lISPw_EDHtkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Linear Regression**\n",
        "\n",
        "The goal for this exercise is to train a linear regression model and a logistic regression model on an environmental dataset. \n",
        "\n",
        "For the first case, we want to find a linear regression relating the June Temperature (as the predictand) and the June Pressure (as the predictor).\n",
        "\n"
      ],
      "metadata": {
        "id": "AxNcWHCxG3vI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can address this question using a [linear regression model](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) from scikit. \n",
        "\n",
        "**Q1.) Import the LinearRegression model. Instantiate it and fit it using the A3 dataframes' pressure and temperature.**"
      ],
      "metadata": {
        "id": "7nkw4g5pI3w4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete the code below\n",
        "\n",
        "# Import the LinearRegression model\n",
        "from __.__ import LinearRegression\n",
        "\n",
        "# Instantiate the model\n",
        "lin_reg = LinearRegression()\n",
        "\n",
        "# Load and reshape the input data\n",
        "pressure = A3_df[''].values.reshape(-1,1)\n",
        "\n",
        "# Load the truth data (i.e., the predictant)\n",
        "temperature = \n",
        "\n",
        "# Fit the model\n",
        "lin_reg.fit(_____, ____)\n"
      ],
      "metadata": {
        "id": "sP4qIkhaM1YB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a linear regression model for the temperature and pressure. Let's make some plots to visualize our data and get a qualitative sense of our model.\n",
        "\n",
        "**Q2) Generate a scatter plot with the linear regression plot for our data.**"
      ],
      "metadata": {
        "id": "znzId7C4T3-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete the code below\n",
        "\n",
        "#Instantiate a figure having size 13,6\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Set figure title and axis labels\n",
        "fig.suptitle('June Temperature vs Pressure  in Guayaquil, Ecuador')\n",
        "ax.set_xlabel(\"Pressure (mb)\")\n",
        "ax.set_ylabel(\"Temperature (°C)\")\n",
        "\n",
        "# The colors and styles suggested below are not compulsory, but please avoid \n",
        "# using the default settings.\n",
        "\n",
        "# Make a scatter plot for the pressure (x) and temperature (y). Use color=black,\n",
        "# marker size = 100, and set the marker style to '2'.\n",
        "ax.scatter()\n",
        "\n",
        "# Make a 100 point numpy array between 1008 and 1014 and store it in reg_x. \n",
        "# Reshape it to (-1,1). Hint: numpy has a linear space generator\n",
        "reg_x = \n",
        "\n",
        "# Let's produce a set of predictions from our linear space array.\n",
        "reg_y = lin_reg.predict(reg_x)\n",
        "\n",
        "# Let's plot the regression line using reg_x and reg_y. Set the color to red and\n",
        "# the linewidth to 1.5\n",
        "ax.plot()\n",
        "ax.autoscale(axis='x', tight=True)"
      ],
      "metadata": {
        "id": "d4N8pwJQTMzH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have a qualitative verification of our model - but this is not enough. Let's do some quantitative analyses:\n",
        "\n",
        "**Q3) Print the slope of our model. Find the F-score, p-value, and $R^2$ statistics for our model.**"
      ],
      "metadata": {
        "id": "gZoEKrwba9XY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete the code below\n",
        "\n",
        "# Fetch the slope directly from the linear model. Hint: check the attributes \n",
        "# section of the linear regression model documentation on scikit.\n",
        "slope = \n",
        "\n",
        "# Calculate the F-score and p-value for our dataset.\n",
        "# Hint: check the f_regression option in sklearn.feature_selection\n",
        "fscore, pvalue = \n",
        "\n",
        "# Fetch the R2 value from the lin_reg model. Hint: check built-in score methods\n",
        "R_squared = \n"
      ],
      "metadata": {
        "id": "SCAF7M07h2BH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Classification**\n",
        "\n",
        "Let's use the same dataset to train a classifier for El Niño years. We will use the June temperature and pressure in Guayaquil as the predictors for El Niño. Let's begin by setting up a training and testing dataset. Since the dataset is so small, we'll set aside one each of a random El Niño year and a non-El Niño year for our test dataset, and the remaining points as our trainign dataset."
      ],
      "metadata": {
        "id": "HlVgyHB3RHO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's make our train and test datasets\n",
        "def test_train_split(df, rnd_gen):\n",
        "    nino_years = df.loc[df['El Niño']==1].index.values\n",
        "    not_nino_years = df.loc[df['El Niño']==0].index.values\n",
        "\n",
        "    nino_idxs = rnd_gen.permutation(np.arange(0,nino_years.size))\n",
        "    not_nino_idxs = rnd_gen.permutation(np.arange(0,not_nino_years.size))\n",
        "\n",
        "    train = ( list(nino_years[nino_idxs[:-1]]) +\n",
        "              list(not_nino_years[not_nino_idxs[:-1]]) )\n",
        "  \n",
        "    test = [nino_years[nino_idxs[-1]], not_nino_years[not_nino_idxs[-1]]]\n",
        "    \n",
        "    return (np.array(test), np.array(train))\n",
        "\n",
        "# Use test_train_split to make the testing and training datasets\n",
        "test, train = test_train_split(A3_df, rnd_gen)\n",
        "print(test, train)"
      ],
      "metadata": {
        "id": "sSkdSpL9rFh8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to train a logistic regression classifier on the dataset, but in this exercise we'll rely on the scikit learn implementation!\n",
        "\n",
        "**Q4) Import and instantiate the logistic regression classifier from scikit. Fit it using the training dataset.**"
      ],
      "metadata": {
        "id": "iIlhTA13wTY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here\n",
        "# Hint: use the dataframes' .loc method with the test/train list, then convert\n",
        "# to numpy and .ravel() the truth if necessary"
      ],
      "metadata": {
        "id": "z95Vova3wcEJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That should hopefully have felt much simpler than our previous exercise. Now that you have a trained model, let's see if our model is able to predict whether the test years are El Niño years!\n",
        "\n",
        "**Q5) Predict whether each of the two test years was an El Niño year using the logistic regression model, and print out the prediction alongside the truth.**"
      ],
      "metadata": {
        "id": "cPUIuMA72-6S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code here"
      ],
      "metadata": {
        "id": "E3R8lsLjwnv6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}