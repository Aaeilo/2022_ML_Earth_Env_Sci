{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tbeucler/2022_ML_Earth_Env_Sci/blob/main/Lab_Notebooks/S2_1_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "_This notebook will be used in the lab session for week 2 of the course, covers Chapters 3 of Géron, and builds on the [notebooks made available on _Github_](https://github.com/ageron/handson-ml2).\n",
        "\n",
        "Need a reminder of last week's labs? Click [_here_](https://github.com/tbeucler/2022_ML_Earth_Env_Sci/blob/main/Lab_Notebooks/Week_1_Basics_of_Python.ipynb) to go to notebook for week 1 of the course."
      ],
      "metadata": {
        "id": "8abwZImbXkN9"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KBWUKJQoRbu"
      },
      "source": [
        "##**Chapter 3 – Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lD-aIdpMoRbw"
      },
      "source": [
        "<table align=\"left\">\n",
        "  <td align=middle>\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/ageron/handson-ml2/blob/master/03_classification.ipynb\"> Open the original notebook <br><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "  </td>\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_2m3XdPZoRbx"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILS2ik8soRby"
      },
      "source": [
        "First, let's import a few common modules, ensure MatplotLib plots figures inline and prepare a function to save the figures. We also check that Python 3.5 or later is installed (although Python 2.x may work, it is deprecated so we strongly recommend you use Python 3 instead), as well as Scikit-Learn ≥0.20.\n",
        "\n",
        "You don't need to worry about understanding everything that is written in this section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0xzMrm7coRby"
      },
      "outputs": [],
      "source": [
        "# Python ≥3.5 is required\n",
        "import sys\n",
        "assert sys.version_info >= (3, 5)\n",
        "\n",
        "# Is this notebook running on Colab or Kaggle?\n",
        "IS_COLAB = \"google.colab\" in sys.modules\n",
        "\n",
        "# Scikit-Learn ≥0.20 is required\n",
        "import sklearn\n",
        "assert sklearn.__version__ >= \"0.20\"\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "rnd_seed = 42\n",
        "rnd_gen = np.random.default_rng(rnd_seed)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \".\"\n",
        "CHAPTER_ID = \"classification\"\n",
        "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\", CHAPTER_ID)\n",
        "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
        "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format=fig_extension, dpi=resolution)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to load the MNIST dataset from OpenML - we won't be loading it as a Pandas dataframe, but will instead use the Dictionary / ndrray representation."
      ],
      "metadata": {
        "id": "KbNW5dKWMIYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Load the mnist dataset\n",
        "from sklearn.datasets import fetch_openml\n",
        "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
        "\n",
        "X = mnist['data']\n",
        "y = mnist['target'].astype(np.uint8)"
      ],
      "metadata": {
        "id": "ar25DAokMIgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Originally, Géron uses the entire MNIST dataset, which can take too long when training several models. As a result, we will generate and use a smaller set of data, taking care to balance it."
      ],
      "metadata": {
        "id": "ADLkHNo6M9fr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generating a smaller balanced dataset for faster computation speed\n",
        "\n",
        "# Per digit sample size\n",
        "balanced_size = 1000\n",
        "\n",
        "# Placeholder Vars\n",
        "bal_X = None\n",
        "bal_y = None\n",
        "\n",
        "# Looping through digit types\n",
        "for digit in np.arange(0,10):\n",
        "  # find indices where target is digit of interest\n",
        "  y_idxs = y==digit\n",
        "  print(f'{digit} has {y_idxs.sum()} instances in the dataset')\n",
        "  \n",
        "  # rnd_gen.choice chooses n = balanced_size indices from the set of digits \n",
        "  # available. Since we know the truth is an array with the same number of rows\n",
        "  # as the subset, full of the current digit \n",
        "  X_subset = X[y_idxs][rnd_gen.choice(np.arange(y_idxs.sum()),(balanced_size,))]\n",
        "  y_subset = np.full(X_subset.shape[0],digit)\n",
        "\n",
        "  if type(bal_X) == type(None):\n",
        "    bal_X = X_subset\n",
        "    bal_y = y_subset\n",
        "  else:\n",
        "    bal_X = np.vstack([bal_X, X_subset])\n",
        "    bal_y = np.hstack((bal_y,y_subset))\n",
        "\n",
        "# Shuffling the dataset\n",
        "shuffler = rnd_gen.permutation(len(bal_X))\n",
        "bal_X = bal_X[shuffler]\n",
        "bal_y = bal_y[shuffler]"
      ],
      "metadata": {
        "id": "GWXIhYT7K1rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the dataset into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# set % of data to be used for testing\n",
        "test_size=.10\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(bal_X, \n",
        "                                                    bal_y, \n",
        "                                                    test_size = test_size, \n",
        "                                                    random_state = rnd_seed)"
      ],
      "metadata": {
        "id": "pJWR-DAQKeHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test that the label and image match. We're using np.random instead of our \n",
        "# rnd_gen since we don't want the runs of this snippet to vary the results in\n",
        "# other snippets :) Run this as many times as you want!\n",
        "test = np.random.randint(0,len(bal_X))\n",
        "plt.imshow(bal_X[test].reshape((28,28)), cmap='Greys')\n",
        "print(f'The image should be of a {bal_y[test]}')"
      ],
      "metadata": {
        "id": "BN84I4gL6ByR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO6vNK6eoRcb"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GdoFhGChoRcc"
      },
      "source": [
        "## 3.1) An MNIST Classifier With 97% Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9UOfRIKoRcc"
      },
      "source": [
        "For this exercise, we will look for the model with the best performance using Scikit's [`Grid Search`](https://duckduckgo.com/?q=gridsearchCV), which performs a \"round robin\" search on a set of possible hyperparameters to find the model with the best performance.\n",
        "\n",
        "Search for Scikit's [`K-neighbors Classifier`](https://duckduckgo.com/?q=scikit+kneighbors) to find the documentation page. You will find a list of parameters that users can use when making the classifier.\n",
        "\n",
        "**Questions:**\n",
        "\n",
        "1. Define a list of dictionaries with the set of hyperparameters that are to be tested: \n",
        "<table align='middle'>\n",
        "  <tr>\n",
        "    <th> Hyper-Parameter</th>\n",
        "    <th colspan=\"5\" scope=\"colgroup\">Values to Test</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td scope=\"col\" align='middle'>Weights</td>\n",
        "    <td scope=\"col\" colspan=\"2\" align='middle'><i>uniform</i></td>\n",
        "    <td scope=\"col\" colspan=\"2\" align='middle'><i>distance</i></td>\n",
        "  </tr>\n",
        "    <tr>\n",
        "    <td scope=\"col\" align='middle'># of Neighbors</td>\n",
        "    <td scope=\"col\" align='middle'><i>3</i></td>\n",
        "    <td scope=\"col\" align='middle'><i>4</i></td>\n",
        "    <td scope=\"col\" align='middle'><i>5</i></td>\n",
        "    <td scope=\"col\" align='middle'><i>6</i></td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "2. Instantiate the KNeighborsClassifier Model\n",
        "\n",
        "3. Fit the models to your training data\n",
        "\n",
        "4. Extract the optimal model parameters\n",
        "\n",
        "5. Evaluate your best model\n",
        "\n",
        "\n",
        "**Bonus:**\n",
        "\n",
        "1. Train and evaluate the models using precision as the metric\n",
        "\n",
        "2. Extract & plot instances in which the model was confused \n",
        "\n",
        "3. Create an imbalanced dataset and study the effect on the model\n",
        "\n",
        "<br><br>Let's begin!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_b1g55_oRcc"
      },
      "outputs": [],
      "source": [
        "# Begin by importing the KNeighersClassifier and GridSearchCV from scikit.\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1) Set up the parameter dictionary** "
      ],
      "metadata": {
        "id": "d0G-qizZNaWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "param_grid = {'weights':[], 'n_neighbors':[]}"
      ],
      "metadata": {
        "id": "IZjW2OdLNagU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q2) Make an instance of the KNeighborsClassifier model**"
      ],
      "metadata": {
        "id": "CWiDG9byNuqB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete the code\n",
        "knn_clf = "
      ],
      "metadata": {
        "id": "S9497-2HNvHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a grid search using the knn_clf model and param grid. We will set the number of folds for the cross-validation to 6, and use the most verbose setting to get the best idea of how well each cv run performs. <br> **Q3) Use GridSearch's fit method to train your models.**"
      ],
      "metadata": {
        "id": "RIFSOGcsN-J_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We define a grid search using the knn_clf model and param grid. We will set\n",
        "# the number of folds for the cross-validation to 6, and use the most verbose\n",
        "# setting to get the best idea of how well each cv run performs.\n",
        "grid_search = GridSearchCV(knn_clf, param_grid, cv=6, verbose=3)\n",
        "\n",
        "#Complete the code\n",
        "grid_search.fit(____,____)\n",
        "\n"
      ],
      "metadata": {
        "id": "sXxafCooN9z6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the models have been trained, let's figure out which one is the best one. <br>\n",
        "**Q4) Fetch and print the optimal parameters and best score using .best_params_  and .best_score_**"
      ],
      "metadata": {
        "id": "mS1jFsIAy2JK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# write your code here"
      ],
      "metadata": {
        "id": "nFNiFrmwTEco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now it's time to test your model! Let's import the [accuracy score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html?highlight=accuracy%20score#sklearn.metrics.accuracy_score) metric from scikit and see how our model fares."
      ],
      "metadata": {
        "id": "9L_cUs03eOSJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t6ma4S4XoRcd"
      },
      "outputs": [],
      "source": [
        "#Import the accuracy metric\n",
        "from sklearn.metrics import accuracy_score\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ODZR4AanUkGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# R5.) Use the grid_search's predict method to predict the targets from the \n",
        "#      test dataset. This will let you evaluate the accuracy of your model!\n",
        "y_pred = grid_search.predict(______)\n",
        "accuracy = accuracy_score(_____, _____)\n",
        "\n",
        "print(f'The accuracy of the model is {accuracy:.1%}')"
      ],
      "metadata": {
        "id": "BHNXSm4zUeVD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Challenges:\n",
        "\n",
        "* **CQ1.)** We trained and tested the model's performance using accuracy as the metric. What happens when you use precision as the scoring metric instead? Note: you'll have to redefine the grid_search scoring parameter\n",
        "\n",
        "* **CQ2.)** Extract some samples that the model made a mistake on and plot them. Can you tell what the digit is?\n",
        "\n",
        "* **CQ3.)** In the setup we reduced the size of the dataset while ensuring that it remained (perfectly) balanced. What happens to the performance of the model when using an unbalanced dataset? Make one of the digits dominate the dataset (e.g., making over 50% of the dataset one of the digits) and try training the algorithm and test it on the _balanced_ test dataset. \n",
        "\n",
        "\n",
        "> **Important!** <br> \n",
        "> Don't write over X_bal and y_bal, as we'll be using them in exercise 2!   "
      ],
      "metadata": {
        "id": "biz6XE2AUiH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code for challenge 1 here"
      ],
      "metadata": {
        "id": "D-2uoAZ3Uhxs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code for challenge 2 here"
      ],
      "metadata": {
        "id": "98aydPF9Uhqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Write your code for challenge 3 here"
      ],
      "metadata": {
        "id": "VYJLoweHUeHI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A2iohebZoRcd"
      },
      "source": [
        "## 2. Data Augmentation\n",
        "In this exercise, we will give [data augmentation](https://en.wikipedia.org/wiki/Data_augmentation) a try, using the smaller mnist dataset we used in the previous exercise. The type of augmentation we'll be using is _shifting_, in which the images in the dataset are shifted up/down/left/right by a number of pixels to make \"new\" datapoints. \n",
        "\n",
        "**Required:**\n",
        "\n",
        "6. Augment the digit dataset using shifted versions of the images\n",
        "\n",
        "7. Train a KneighborsClassifier model on the augmented data set using the best parameters found in Exercise 1\n",
        "\n",
        "8. Evaluate the accuracy of the model trained with the augmented data\n",
        "\n",
        "**Challenges:**\n",
        "\n",
        "5. Implement a rotation augmentation strategy\n",
        "\n",
        "6. (Prerequesite: C3) Try addressing the imbalance in the dataset using data augmentation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6GjQXb4IoRcd"
      },
      "outputs": [],
      "source": [
        "# We will import shift form the scipy multi-dimensional image processing tools\n",
        "from scipy.ndimage.interpolation import shift\n",
        "\n",
        "# Using shift, we will write a function that shifts a single image left or right\n",
        "def shift_image(image, dx, dy):\n",
        "    image = image.reshape((28, 28))\n",
        "    shifted_image = shift(image, [dy, dx], cval=0, mode=\"constant\")\n",
        "    return shifted_image.reshape([-1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYGb-Q0IoRce"
      },
      "outputs": [],
      "source": [
        "# We will pull out a single image to showcase the use of shift_image \n",
        "rnd_id = rnd_gen.integers(0,X_train.shape[0])\n",
        "\n",
        "plt.figure(figsize=(12,3))\n",
        "\n",
        "# Load and plot the original image\n",
        "image = X_train[rnd_id]\n",
        "plt.subplot(131)\n",
        "plt.title(\"Original\", fontsize=14)\n",
        "plt.imshow(image.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
        "\n",
        "# shift the original image down and plot it\n",
        "shifted_image_down = shift_image(image, 0, 5)\n",
        "plt.subplot(132)\n",
        "plt.title(\"Shifted down\", fontsize=14)\n",
        "plt.imshow(shifted_image_down.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
        "\n",
        "# shift the original image left and plot it\n",
        "shifted_image_left = shift_image(image, -5, 0)\n",
        "plt.subplot(133)\n",
        "plt.title(\"Shifted left\", fontsize=14)\n",
        "plt.imshow(shifted_image_left.reshape(28, 28), interpolation=\"nearest\", cmap=\"Greys\")\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neHmqABXoRce"
      },
      "outputs": [],
      "source": [
        "# transform the datasets into lists of images for iterating & appending\n",
        "X_train_augmented = [image for image in X_train]\n",
        "y_train_augmented = [label for label in y_train]\n",
        "\n",
        "# Make a tuple of shifts to apply to the datasets as augmentation.\n",
        "# a shift of 1 pixel up, down, left, and right are recommended.\n",
        "shifts = ((__,__),(__,__), ...)\n",
        "\n",
        "for dx, dy in shifts:\n",
        "    for image, label in zip(X_train, y_train):\n",
        "        X_train_augmented.append(shift_image(image, dx, dy))\n",
        "        y_train_augmented.append(label)\n",
        "\n",
        "# Transform the lists back into numpy arrays\n",
        "X_train_augmented = np.array(X_train_augmented)\n",
        "y_train_augmented = np.array(y_train_augmented)\n",
        "\n",
        "# The augmented data still needs to be shuffled\n",
        "aug_shuffler = rnd_gen.permutation(len(X_train_augmented))\n",
        "X_train_augmented = X_train_augmented[aug_shuffler]\n",
        "y_train_augmented = y_train_augmented[aug_shuffler]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have an augmented dataset! Let's train a model using the best hyperparameters we previously found with our grid search.\n",
        "\n",
        "**Q6) Load a new K Nearest Neighbors classifier using the .best_params_ information**"
      ],
      "metadata": {
        "id": "906YYXEKYONa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete the code\n",
        "knn_clf = KNeighborsClassifier()"
      ],
      "metadata": {
        "id": "4Wj8wnDvYkMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q7) Fit the new model using the augmented x and y data**"
      ],
      "metadata": {
        "id": "kgvouf4lY7W3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#write your code here"
      ],
      "metadata": {
        "id": "VPdXnVpjY7hk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q8) Evaluate the accuracy of the model trained with the augmented data**"
      ],
      "metadata": {
        "id": "7i9vguyYZM41"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Complete the code\n",
        "y_pred = grid_search.predict(______)\n",
        "accuracy = accuracy_score(_____, _____)"
      ],
      "metadata": {
        "id": "8mcDqCEPZTMi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Challenges:\n",
        "\n",
        "* **CQ4.)**We've implemented a shift strategy, but there's a myriad of ways of augmenting your dataset! Try implementing a rotation augmentation strategy using Scipy's ndimage.rotate\n",
        "\n",
        "* **CQ5.)** We've implemented shifts as augmentations in the dataset. In a previous challenge we developed an unbalanced dataset - try addressing the imbalance in the dataset by augmenting the dataset!"
      ],
      "metadata": {
        "id": "4FM8ZY7yZs0_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLmrLSJHoRce"
      },
      "outputs": [],
      "source": [
        "# Write your code for challenge 4 here "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code for challenge 5 here"
      ],
      "metadata": {
        "id": "-LU0BkymaIMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86ThswH3oRcf"
      },
      "source": [
        "## 3.2) Tackling the Titanic dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yy2P3nToRcf"
      },
      "source": [
        "In this exercise we will be attempting to predict whether or not a passenger on the titanic survived or not, based on their attributes (e.g., age, sex, passenger class, where they embarked, and so on). For this exercise, we will be relying on [Pandas](https://en.wikipedia.org/wiki/Pandas_(software)) [DataFrames](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html).\n",
        "\n",
        "**Required:**\n",
        "\n",
        "9. Calculate the mean of the age the corresponding standard deviation for the female and male populations in the passenger list. \n",
        "\n",
        "10. Set up a pipeline for the numerical attributes that implements an \"median\" imputer and a scaler \n",
        "\n",
        "11. Set up a pipeline for the categorical attributes that implements a \"most frequent\" imputer and a one-hot categorical encoder\n",
        "\n",
        "12. Prepare the training and testing datasets for the Titanic data. What's the difference between `.fit_transform()` and `.transform()` ?\n",
        "\n",
        "13. Train a random forest classifier with 100 estimators \n",
        "\n",
        "14. Make a prediction using the trained random forest classifier. How good is the accuracy? \n",
        "\n",
        "15. Compare this to a 10-fold cross validation mean.\n",
        "\n",
        "16. Train a support-vector clustering algorithm and compare its 10-fold cross validation mean to that of the random forest classifier.\n",
        "\n",
        "**Challenges:**\n",
        "\n",
        "6. Choose two other models and try using them to predict whether or not a passenger would survive. Use grid-search to try out several hyperparameters and determine which model worked best out of the four.\n",
        "\n",
        "7. Try converting numerical attributes to categorical attributes, such as age group instead of age, or those travelling alone vs with company."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mm_4pFmkoRcf"
      },
      "source": [
        "Let's begin by fetching the data from the internet and loading it into memory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LwggUBydoRcf"
      },
      "outputs": [],
      "source": [
        "# Setup - We need to fetch the data from the internet\n",
        "import os\n",
        "import urllib.request\n",
        "\n",
        "TITANIC_PATH = os.path.join(PROJECT_ROOT_DIR,\"datasets\", \"titanic\")\n",
        "DOWNLOAD_URL = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/datasets/titanic/\"\n",
        "\n",
        "def fetch_titanic_data(url=DOWNLOAD_URL, path=TITANIC_PATH):\n",
        "    if not os.path.isdir(path):\n",
        "        os.makedirs(path)\n",
        "    for filename in (\"train.csv\", \"test.csv\"):\n",
        "        filepath = os.path.join(path, filename)\n",
        "        if not os.path.isfile(filepath):\n",
        "            print(\"Downloading\", filename)\n",
        "            urllib.request.urlretrieve(url + filename, filepath)\n",
        "\n",
        "fetch_titanic_data()    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yAMH0rymoRcg"
      },
      "outputs": [],
      "source": [
        "# We further need to load the Titanic data into memory.\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "def load_titanic_data(filename, titanic_path=TITANIC_PATH):\n",
        "    csv_path = os.path.join(titanic_path, filename)\n",
        "    return pd.read_csv(csv_path)\n",
        "\n",
        "train_data = load_titanic_data(\"train.csv\")\n",
        "test_data = load_titanic_data(\"test.csv\")\n",
        "\n",
        "# We will explicitely set the PassengerId attribute as the DataFrame index \n",
        "# since it is unique to each passenger\n",
        "train_data = train_data.set_index(\"PassengerId\")\n",
        "test_data = test_data.set_index(\"PassengerId\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s8_6YueUoRcg"
      },
      "source": [
        "The data is already split into a training set and a test set. However, *the test data* does **not** contain the labels: your goal is to train the best model you can using the training data, then make your predictions on the test data.\n",
        "\n",
        "Let's take a peek at the training set. Use the `.head()` method to return the first 5 rows of the training dataset. \n",
        "\n",
        "*If you're on colab, you can instead use Google's interactive data table!*\n",
        "\n",
        "-----------------------\n",
        "\n",
        "The dataset should include the following attributes:\n",
        "* **PassengerId**: a unique identifier for each passenger\n",
        "* **Survived**: that's the target, 0 means the passenger did not survive, while 1 means he/she survived.\n",
        "* **Pclass**: passenger class.\n",
        "* **Name**, **Sex**, **Age**: self-explanatory\n",
        "* **SibSp**: how many siblings & spouses of the passenger aboard the Titanic.\n",
        "* **Parch**: how many children & parents of the passenger aboard the Titanic.\n",
        "* **Ticket**: ticket id\n",
        "* **Fare**: price paid (in pounds)\n",
        "* **Cabin**: passenger's cabin number\n",
        "* **Embarked**: where the passenger embarked the Titanic. C=Cherbourg, Q=Queenstown, S=Southampton."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijFp0ONWoRcg"
      },
      "outputs": [],
      "source": [
        "# Load Google's data table to display the dataframe interactively\n",
        "from google.colab import data_table\n",
        "data_table.DataTable(train_data, num_rows_per_page=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using DataFrames allow us to easily calculate statistics from the data. Here we will use the .median() and .std() methods to get an picture of the passenger population."
      ],
      "metadata": {
        "id": "rhbhBw6wJ1u3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q9) Calculate the median and standard deviation for each listed sex category**"
      ],
      "metadata": {
        "id": "KbsuCAnRbwiC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V1rpcp1doRci"
      },
      "outputs": [],
      "source": [
        "# Complete the code\n",
        "med_age_f = train_data[train_data[\"___\"]==\"___\"][\"___\"].median()\n",
        "stddev_age_f = \n",
        "med_age_m = \n",
        "stddev_age_m = \n",
        "\n",
        "print_out=(f'The female population had a median age of {med_age_f:.1f}'\n",
        "           f' with a standard deviation of {stddev_age_f:.2f} \\n'\n",
        "           f'The male population had a median age of {med_age_m:.1f}'\n",
        "           f' with a standard deviation of {stddev_age_m:.2f} \\n')\n",
        "\n",
        "print(print_out)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6h5nn-XhoRch"
      },
      "source": [
        "It's important that we be aware of the gaps in the data available. In order to do this, let's rely on the DataFrames `.info()` method:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T2YZzTZaoRch"
      },
      "outputs": [],
      "source": [
        "train_data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fg8WxPoBoRci"
      },
      "source": [
        "Okay, the **Age**, **Cabin** and **Embarked** attributes are sometimes null (less than 891 non-null), especially the **Cabin** (77% are null). We will ignore the **Cabin** for now and focus on the rest. The **Age** attribute has about 19% null values, so we will need to decide what to do with them. One reasonable option is to replace null values with the median age. We could be a bit smarter by predicting the age based on the other columns (for example, the median age is 37 in 1st class, 29 in 2nd class and 24 in 3rd class), but we'll keep things simple and just use the overall median age. \n",
        "\n",
        "(Note: this will be done in a later step, when we develop the data pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdLtswehoRci"
      },
      "source": [
        "The **Name** and **Ticket** attributes may have some value, but they will be a bit tricky to convert into useful numbers that a model can consume. So for now, we will ignore them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0UO0IrpoRci"
      },
      "source": [
        "Let's take a look at the numerical attributes:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2_crvx0oRci"
      },
      "outputs": [],
      "source": [
        "train_data.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KgM5Yvp7oRci"
      },
      "source": [
        "* Less than 50% of the passengers survived (About 38%, to be more precise). That's close enough to 40%, so accuracy will be a reasonable metric to evaluate our model.\n",
        "* The mean **Fare** was £32.20, which does not seem so expensive, but the [Bank of England estimates](https://www.bankofengland.co.uk/monetary-policy/inflation/inflation-calculator) the value to be around _£3889_ in 2021.\n",
        "* The mean **Age** was a little under 30 years old.\n",
        "* Over half of the passengers were in 3rd Class "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Cs27CWRoRci"
      },
      "source": [
        "We will now verify that the `Survived` class is indeed 0 or 1. \n",
        "\n",
        "We will also look at the types of values we have in our categorical variables, namely:  `Passenger Class`, `Sex`, and `Embarqued`.\n",
        "\n",
        "Reminder: \n",
        "The Embarked attribute tells us where the passenger embarked: C=Cherbourg, Q=Queenstown, S=Southampton."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQ5WkkNqoRcj"
      },
      "outputs": [],
      "source": [
        "print_out = \"\"\n",
        "var_list = [\"Survived\", \"Pclass\", \"Sex\", \"Embarked\"]\n",
        "for var in var_list: print_out += f'{train_data[var].value_counts()} \\n\\n'\n",
        "\n",
        "print(print_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1AvRyGPoRcj"
      },
      "source": [
        "Now let's build our [data preprocessing pipelines](https://en.wikipedia.org/wiki/Data_pre-processing), starting with the pipeline for numerical attributes.\n",
        "In this section we will set up a [Pipeline class](https://duckduckgo.com/?q=sklearn+pipeline), which will fill the missing values in the columns using the mean value (see the [SimpleImputer documentation](https://duckduckgo.com/?q=sklearn+simpleimputer)) and scale the data (see the [StandardScaler documentation](https://duckduckgo.com/?q=sklearn+standardscaler))."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q10) Set up the numerical attribute pipeline using a) an \"imputer\" that uses SimpleImputer with \"median\" set as the strategy and b) a \"scaler\" that uses a default StandardScaler**"
      ],
      "metadata": {
        "id": "EMYdu1iZduv4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PadFWbBzoRcj"
      },
      "outputs": [],
      "source": [
        "# Complete the code\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# The Pipeline needs to be initiated with a list containing the name of the\n",
        "# preprocessor (e.g., \"imputer\" or \"scaler\").\n",
        "num_pipeline = Pipeline( [ (\"\", _________(_________=\"\")),\n",
        "                           (\"\", _________()) ] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y5K9Y4IzoRcj"
      },
      "source": [
        "Now we can build the pipeline for the categorical attributes. Here, we will use [one-hot encoding](https://en.wikipedia.org/wiki/One-hot#Machine_learning_and_statistics) using the [OneHotEncoder](https://duckduckgo.com/?q=sklearn+onehotencoder) preprocessor in Scikit.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q11) Set up the categorical attribute pipeline using: a) an \"imputer\" that uses SimpleImputer with \"most_frequent\" set as the strategy and b) a \"cat_encoder\" that uses a OneHotEncoder with the sparse parameter set to *False***"
      ],
      "metadata": {
        "id": "v7xDH4G8dsIN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8cxUS4TzoRck"
      },
      "outputs": [],
      "source": [
        "# Complete the code\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "cat_pipeline = Pipeline( [ (\"\", _________(_________=\"\")),\n",
        "                           (\"\", _________(_________=\"\")) ] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtGqgKGzoRck"
      },
      "source": [
        "Finally, let's join the numerical and categorical pipelines using scikit's [ColumnTransformer](https://duckduckgo.com/?q=sklearn+ColumnTransformer):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hP7U2iztoRck"
      },
      "outputs": [],
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "num_attribs = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
        "cat_attribs = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
        "\n",
        "preprocess_pipeline = ColumnTransformer( [(\"num\", num_pipeline, num_attribs),\n",
        "                                          (\"cat\", cat_pipeline, cat_attribs) ] )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxCNJ9q4oRck"
      },
      "source": [
        "We now have a preprocessing pipeline that takes the raw data and outputs numerical input features that we can feed to any Machine Learning model we want, and we can also generate the truth variable from the 'Survived' data.\n",
        "\n",
        "Let's generate our train and test data.\n",
        "\n",
        "--------------------\n",
        "Note! We will continue using X_train, y_train, X_test, and y_test as the variable names for our training and testing datasets. However, the notebook only has one namespace. Thus, runnng the code below will overwrite the X_train/test and y_train/test variables from exercises 1 & 2. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q12) Prepare the training and testing datasets (Remember to load \"Survived\" into y_train!). What's the difference between .fit_transform() and .transform() ?**"
      ],
      "metadata": {
        "id": "TqQ5pAxidpIZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2l2zH2_zoRck"
      },
      "outputs": [],
      "source": [
        "# Complete the code\n",
        "X_train = preprocess_pipeline.fit_transform(\n",
        "              train_data[num_attribs + cat_attribs] )\n",
        "X_test =  \n",
        "\n",
        "y_train = \n",
        "\n",
        "y_test = \n",
        "\n",
        "#Let's print a sample to take a loot at the data being produced\n",
        "for idx, attrib in np.ndenumerate(np.hstack((num_attribs,cat_attribs))):\n",
        "    print(f\"{attrib} has a value of {X_train[0][idx]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11NFNA-MoRcl"
      },
      "source": [
        "Now that we've finally prepared the pipeline, we can begin training algorithms!\n",
        "Let's start by training a type of classifier called a [`RandomForestClassifier`](https://duckduckgo.com/?q=scikit+randomforestclassifie). This type of a classifier is an _ensemble classifier_, which employs a number of estimators that we have to define. Today, we will use 100 members in our ensemble."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q13) Import a RandomForestClassifier from scikit and instantiate it with 100 estimators. Then, fit the model**"
      ],
      "metadata": {
        "id": "kp6Zc3b2mlJc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2YtFhjJoRcl"
      },
      "outputs": [],
      "source": [
        "# Complete the code\n",
        "from sklearn._______ import ______\n",
        "\n",
        "forest_clf = RandomForestClassifier(______, random_state=rnd_seed)\n",
        "forest_clf.___(___,___)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfCfaWOMoRcl"
      },
      "source": [
        "Great, our model is trained! Let's use it to make predictions on the test set. Let's also check the accuracy of our model on the test dataset.\n",
        "\n",
        "**Q14) Predict a set of answers using the trained model and compare it using the *accuracy_score* metric. Then, print out a statement reporting the accuracy**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScTILYjroRcl"
      },
      "outputs": [],
      "source": [
        "#Complete the code\n",
        "y_pred =\n",
        "\n",
        "from ____.___ import accuracy_score\n",
        "\n",
        "print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRkCsk6IoRcm"
      },
      "source": [
        "Our model gave us a prediction and we were able to compare how accurate our predictions were, but we're also interested in knowing how good our model is. After all, we wouldn't want to risk us being \n",
        "\n",
        "And now we could just build a CSV file with these predictions (respecting the format excepted by Kaggle), then upload it and hope for the best. But wait! We can do better than hope. Why don't we use cross-validation to have an idea of how good our model is?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15) Import the cross_val_score function and produce a set of 10-fold cross validation scores using the training data. Then, print the mean score. How does it compare with the answer to Q14?**"
      ],
      "metadata": {
        "id": "g2WsNkRqoCBf"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMO4Cp0VoRcm"
      },
      "outputs": [],
      "source": [
        "# Complete the code\n",
        "from ____.____ import cross_val_score\n",
        "\n",
        "forest_scores = cross_val_score(__, __, __, __)\n",
        "\n",
        "print(f'The mean score is {}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRPB-By6oRcm"
      },
      "source": [
        "We will now compare to the [leaderboard](https://www.kaggle.com/c/titanic/leaderboard) for the Titanic competition on Kaggle. How does our model compare?\n",
        "\n",
        "Don't be discouraged by those with 100% accuracy - since you can easily find the [list of victims](https://www.encyclopedia-titanica.org/titanic-victims/) of the Titanic, it seems likely that there was little Machine Learning involved in their performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BaM_MPCPoRcm"
      },
      "source": [
        "Let's move on from random forests and try an `SVC`, i.e., a [support-vector clustering algorithm](https://www.jmlr.org/papers/volume2/horn01a/horn01a.pdf)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q15) Train a support-vector clustering algorithm and generate a set of cross-validated scores**"
      ],
      "metadata": {
        "id": "GWIdOxoiogP9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0OpdmMxoRcm"
      },
      "outputs": [],
      "source": [
        "# Complete the code\n",
        "\n",
        "# Let's import the SVC class and instantiate a model\n",
        "from sklearn.svm import SVC\n",
        "svm_clf = SVC(gamma=\"auto\")\n",
        "\n",
        "svm_scores = \n",
        "print(f'The mean score is {}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PSnIqjcJoRcm"
      },
      "source": [
        "If everything went well, this model should look better. Notice though that what we've printed so far is the mean score from the cross validation. While we do appreciate models having higher mean accuracy, consistency is also very important when making predictions! Let's visualize the scores using a box plot (Géron thanking Nevin Yilmaz as the proponents of this idea), where the points will represent the performance on the testing fold in each run. \n",
        "\n",
        "It's also important to note that the `boxplot()` function detects outliers (called \"fliers\") and does not include them within the whiskers. Specifically, if the lower quartile is  Q1  and the upper quartile is  Q3 , then the interquartile range  IQR=Q3−Q1  (this is the box's height), and any score lower than  Q1−1.5×IQR  is a flier, and so is any score greater than  Q3+1.5×IQR . "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7fDElKMoRcn"
      },
      "source": [
        "But instead of just looking at the mean accuracy across the 10 cross-validation folds, let's plot all 10 scores for each model, along with a box plot highlighting the lower and upper quartiles, and \"whiskers\" showing the extent of the scores (thanks to Nevin Yilmaz for suggesting this visualization). Note that the `boxplot()` function detects outliers (called \"fliers\") and does not include them within the whiskers. Specifically, if the lower quartile is $Q_1$ and the upper quartile is $Q_3$, then the interquartile range $IQR = Q_3 - Q_1$ (this is the box's height), and any score lower than $Q_1 - 1.5 \\times IQR$ is a flier, and so is any score greater than $Q3 + 1.5 \\times IQR$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tdAWlGBIoRcn"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "plt.plot([1]*10, svm_scores, \".\")\n",
        "plt.plot([2]*10, forest_scores, \".\")\n",
        "plt.boxplot([svm_scores, forest_scores], labels=(\"SVM\",\"Random Forest\"))\n",
        "plt.ylabel(\"Accuracy\", fontsize=14)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5n3-x2xFoRcn"
      },
      "source": [
        "If all goes as expected, the random forest classifier should have gotten a very high score on one of the 10 folds, but overall should have a lower mean score and a bigger spread. This suggests that the SVM classifier is more likely to generalize well."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Challenges\n",
        "\n",
        "* **C6)** Choose two other models and try using them to predict whether or not a passenger would survive. Use grid-search to try out several hyperparameters and determine which model worked best out of the four.\n",
        "\n",
        "* **C7)** Try converting numerical attributes to categorical attributes, such as age group instead of age, or those travelling alone vs with company."
      ],
      "metadata": {
        "id": "hPKBoSjkqEeR"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "nav_menu": {},
    "toc": {
      "navigate_menu": true,
      "number_sections": true,
      "sideBar": true,
      "threshold": 6,
      "toc_cell": false,
      "toc_section_display": "block",
      "toc_window_display": false
    },
    "colab": {
      "name": "S2_1_Classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}